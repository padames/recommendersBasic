{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "%matplotlib inline \n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='times')\n",
    "plt.rc('xtick', labelsize=10) \n",
    "plt.rc('ytick', labelsize=10) \n",
    "plt.rc('font', size=12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movielens database has\n",
      "    100000 ratings\n",
      "       943 users\n",
      "      1682 movies.\n",
      "   user_id         title  movie_id  rating release_date sex  age\n",
      "0      196  Kolya (1996)       242       3  24-Jan-1997   M   49\n",
      "1      305  Kolya (1996)       242       5  24-Jan-1997   M   23\n",
      "2        6  Kolya (1996)       242       4  24-Jan-1997   M   42\n",
      "3      234  Kolya (1996)       242       4  24-Jan-1997   M   60\n",
      "4       63  Kolya (1996)       242       3  24-Jan-1997   M   31\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "from math import isnan\n",
    "\n",
    "\n",
    "# Load Data set\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('../data/ml-100k/u.user', sep='|', names=u_cols, encoding='iso-8859-1')\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('../data/ml-100k/u.data', sep='\\t', names=r_cols,  encoding='iso-8859-1')\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first three columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date']\n",
    "movies = pd.read_csv('../data/ml-100k/u.item', sep='|', names=m_cols, usecols=range(3), encoding='iso-8859-1')\n",
    "\n",
    "# Construccion del DataFrame\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "print(\"The movielens database has\\n\"\n",
    "    +\"    \" + str(data.shape[0]) + \" ratings\\n\"\n",
    "    +\"      \", data.user_id.nunique(),\"users\\n\"\n",
    "    +\"     \", data.movie_id.nunique(), \"movies.\")\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimPearson' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b5a8b7dd7653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCollaborativeFiltering3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;34m\"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b5a8b7dd7653>\u001b[0m in \u001b[0;36mCollaborativeFiltering3\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m\"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSimPearson\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_common_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_sim_users\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;34m\"\"\" Constructor \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;31m# Gets recommendations for a person by using a weighted average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SimPearson' is not defined"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def par_similarity_calc(sim_obj, user_list):\n",
    "    for person1 in user_list:\n",
    "        sim.setdefault(person1, {})\n",
    "        a = data_train[data_train['user_id']==person1][['movie_id']]\n",
    "        data_reduced = pd.merge(data_train, a, on='movie_id')\n",
    "        for person2 in allUsers:\n",
    "            # no es comparem am nosalres mateixos => we don’t compare ourselves to ourselves\n",
    "            if person1 == person2: \n",
    "                continue\n",
    "            self.sim.setdefault(person2, {})\n",
    "            if(person1 in self.sim[person2] ):\n",
    "                continue # since is a simetric matrix\n",
    "            sim=self.sim_method(data_reduced, person1, person2, self.min_common_items)\n",
    "            #print person1,person2,sim\n",
    "            if(sim<0):\n",
    "                self.sim[person1][person2] = 0\n",
    "                self.sim[person2][person1] = 0\n",
    "            else:\n",
    "                self.sim[person1][person2] = sim\n",
    "                self.sim[person2][person1] = sim\n",
    "\n",
    "    \n",
    "class CollaborativeFiltering3:\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "    \n",
    "    def __init__(self,DataFrame, similarity=SimPearson,min_common_items=10,max_sim_users=10):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_method=similarity# Gets recommendations for a person by using a weighted average\n",
    "        self.df=DataFrame\n",
    "        self.sim = pd.DataFrame(np.sum([0]), columns=data_train.user_id.unique(), \\\n",
    "                                index=data_train.user_id.unique())\n",
    "        self.min_common_items=min_common_items\n",
    "        self.max_sim_users=max_sim_users\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\" Prepare data structures for estimation. Similarity matrix for users \"\"\"\n",
    "        allUsers = set(self.df['user_id'])\n",
    "        self.sim = {}\n",
    "        pool = Pool(processes=12)\n",
    "        pool.map(par_similarity_calc, allUsers)\n",
    "        for person1 in allUsers:\n",
    "            self.sim.setdefault(person1, {})\n",
    "            a = data_train[data_train['user_id']==person1][['movie_id']]\n",
    "            data_reduced = pd.merge(data_train, a, on='movie_id')\n",
    "            for person2 in allUsers:\n",
    "                # no es comparem am nosalres mateixos => we don’t compare ourselves to ourselves\n",
    "                if person1 == person2: \n",
    "                    continue\n",
    "                self.sim.setdefault(person2, {})\n",
    "                if(person1 in self.sim[person2] ):\n",
    "                    continue # since is a simetric matrix\n",
    "                sim=self.sim_method(data_reduced, person1, person2, self.min_common_items)\n",
    "                #print person1,person2,sim\n",
    "                if(sim<0):\n",
    "                    self.sim[person1][person2] = 0\n",
    "                    self.sim[person2][person1] = 0\n",
    "                else:\n",
    "                    self.sim[person1][person2] = sim\n",
    "                    self.sim[person2][person1] = sim\n",
    "                \n",
    "        self.mean_ratings = data_train[['user_id','movie_id','rating']] \\\n",
    "                .groupby('user_id')['rating'] \\\n",
    "                .mean()\n",
    "                \n",
    "                \n",
    "    def estimate(self, user_id, movie_id):\n",
    "        \n",
    "        totals={}\n",
    "        movie_users=self.df[self.df['movie_id'] ==movie_id]\n",
    "        rating_num=0.0\n",
    "        rating_den=0.0\n",
    "        allUsers=set(movie_users['user_id'])\n",
    "        listOrdered=sorted([(self.sim[user_id][other],other) for other in allUsers if user_id!=other],reverse=True)\n",
    "        \n",
    "        for item in range(min(len(listOrdered),self.max_sim_users)):\n",
    "            other=listOrdered[item][1]\n",
    "            rating_num += self.sim[user_id][other] * (float(movie_users[movie_users['user_id']==other]['rating']-self.mean_ratings[other]))\n",
    "            rating_den += self.sim[user_id][other]\n",
    "        if rating_den==0: \n",
    "            if self.df.rating[self.df['movie_id']==movie_id].mean()>0:\n",
    "                # return the mean movie rating if there is no similar for the computation\n",
    "                return self.df.rating[self.df['movie_id']==movie_id].mean()\n",
    "            else:\n",
    "                # else return mean user rating \n",
    "                return self.df.rating[self.df['user_id']==user_id].mean()\n",
    "        return self.mean_ratings[user_id]+rating_num/rating_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
